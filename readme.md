**Natural Language Processing**

1. Tokenizing: Seperating of words or sentences.
2. Stop Words: Getting rid of useless words
3. Stemming: Converting all words into similar tense

